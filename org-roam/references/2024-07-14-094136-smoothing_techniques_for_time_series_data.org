:PROPERTIES:
:ID:       c78dca1f-9072-4ef4-b120-81b8d69f9c15
:END:
#+title: Smoothing Techniques for time series data

[[id:b2377ddc-9d91-4c8e-a4d8-21fabf961ee8][Time Series]]
* Introduction
Smoothing techniques are kinds of data preprocessing techniques to remove noise from a data set. This allows important patterns to stand out.
* Moving average (MA) smoothing
It is a simple and common type of smoothing used in time series analysis and forecasting. Here time series derived from the average of last kth elements of the series.

The formula provided is:
$$\[ S_t = \frac{X_{t-k} + X_{t-k+1} + X_{t-k+2} + \ldots + X_t}{k} \]$$
Where:
+ $S_t$ is the smoothed value at time $t$.
+ $X_t$ is the actual value at time $t$.
+ $k$ is the number of periods over which the average is calculated.

#+begin_src python
def moving_avarage_smoothing(X,k):
	S = np.zeros(X.shape[0])
	for t in range(X.shape[0]):
		if t < k:
			S[t] = np.mean(X[:t+1])
		else:
			S[t] = np.sum(X[t-k:t])/k
	return S
#+end_src


* Exponential smoothing
Exponential smoothing is a weighted moving average technique. In the moving average smoothing the past observations are weighted equally, In this case smoothing is done by assigning exponentially decreasing weights to the past observations.

\[
S_0 = X_0
\]

\[
S_t = \alpha \cdot X_t + (1 - \alpha) \cdot S_{t-1} \quad \{ t > 0, \, 0 < \alpha < 1 \}
\]

In the above equation, we can see that $(1 - \alpha)$ is multiplied by the previously expected value $S_{t-1}$ which is derived using the same formula. This makes the expression recursive, and if you were to write it all out on paper, you would quickly see that $(1 - \alpha)$ is multiplied by itself again and again. And this is why this method is called exponential.

#+begin_src python
def exponential_smoothing(X,α):
	S = np.zeros(X.shape[0])
	S[0] = X[0]
	for t in range(1,X.shape[0]):
		S[t] = α * X[t-1] + (1- α) * S[t-1]
	return S
#+end_src


* Double exponential smoothing
Single Smoothing does not excel in the data when there is a trend. This situation can be improved by the introduction of a second equation with a second constant β.

t is suitable to model the time series with the trend but without seasonality.

\[
S_0 = X_0
\]

\[
B_0 = X_1 - X_0
\]

\[
S_t = \alpha \cdot X_t + (1 - \alpha) \cdot (S_{t-1} + B_{t-1})
\]

\[
B_t = \beta \cdot (S_t - S_{t-1}) + (1 - \beta) \cdot B_{t-1}
\]

\[
\alpha, \beta \in (0, 1)
\]

Here it is seen that $\alpha$ is used for smoothing the level and $\beta$ is used for smoothing the trend.

#+begin_src python
def double_exponential_smoothing(X,α,β):
	S,A,B = (np.zeros( X.shape[0] ) for i in range(3))
	S[0] = X[0]
	B[0] = X[1] - X[0]
	for t in range(1,X.shape[0]):
		A[t] = α * X[t] + (1- α) * S[t-1]
		B[t] = β * (A[t] - A[t-1]) + (1 - β) * B[t-1]
		S[t] = A[t] + B[t]
	return S
#+end_src


* Triple exponential smoothing
It is also called as Holt-winters exponential smoothing .it is used to handle the time series data containing a seasonal component.

double smoothing will not work in case of data contain seasonality.so that for smoothing the seasonality a third equation is introduced.


\[
S_0, F_0 = X_0
\]

\[
B_0 = \frac{\sum_{i=0}^{L-1} (X_{L+i} - X_i)}{L^2}
\]

\[
S_t = \alpha \cdot (X_t - C_{\%L}) + (1 - \alpha) \cdot (S_{t-1} + \phi \cdot B_{t-1})
\]

\[
B_t = \beta \cdot (S_t - S_{t-1}) + (1 - \beta) \cdot \phi \cdot B_{t-1}
\]

\[
C_{\%L} = \gamma \cdot (X_t - S_t) + (1 - \gamma) \cdot C_{\%L}
\]

\[
F_{t+m} = S_t + B_t \cdot \sum_{i=1}^{m} \phi^i + C_{\%L}
\]

\[
\alpha, \beta, \gamma \in (0, 1)
\]

In the above, $\phi$ is the damping constant. $\alpha$, $\beta$, and $\gamma$ must be estimated in such a way that the [[id:e4617ee2-3c65-4752-91e6-d2ea8e4e18d8][Root Mean Squared Error (RMSE)]] of the error is minimized.

#+begin_src python
def triple_exponential_smoothing(X,L,α,β,γ,ϕ):

	def sig_ϕ(ϕ,m):
		return np.sum(np.array([np.power(ϕ,i) for i in range(m+1)]))

	C, S, B, F = (np.zeros( X.shape[0] ) for i in range(4))
	S[0], F[0] = X[0], X[0]
	B[0] = np.mean( X[L:2*L] - X[:L] ) / L
	m = 12
	sig_ϕ = sig_ϕ(ϕ,m)
	for t in range(1, X.shape[0]):
		S[t] = α * (X[t] - C[t % L]) + (1 - α) * (S[t-1] + ϕ * B[t-1])
		B[t] = β * (S[t] - S[t-1]) + (1-β) * ϕ * B[t-1]
		C[t % L] = γ * (X[t] - S[t]) + (1 - γ) * C[t % L]
		F[t] = S[t] + sig_ϕ * B[t] + C[t % L]
	return S
#+end_src

* Reference List
1. https://medium.com/@srv96/smoothing-techniques-for-time-series-data-91cccfd008a2
